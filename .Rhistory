z<-a
z<-2
z
load MASS
install.packages('MASS')
?biopsy
load MASS
library(MASS)
?biopsy
summary()
summary(MASS)
summary(biopsy)
print(all())
names(Auto)
nrow(MASS)
train <- sample(x=1:nrow(Auto), size=196, replace=FALSE)
MASS.train = Auto[train,]
MASS.test = Auto[-train,]
nrow(MASS)
train <- sample(x=1:nrow(MASS), size=196, replace=FALSE)
MASS.train = MASS[train,]
MASS.test = MASS[-train,]
#2.3c
MASS.train
#2.3b
nrow(MASS)
names(MASS)
library(MASS)
names(MASS)
rm(list=ls())
#2.3a
install.packages("MASS")
library(MASS)
names(biopsy)
#2.3b
nrow(biopsy)
train <- sample(x=1:nrow(biopsy), size=196, replace=FALSE)
MASS.biopsy = biopsy[train,]
size(biopsy)
length(biopsy)
nrow(biopsy)
train <- sample(x=1:nrow(biopsy), size=nrow(biopsy)/2, replace=FALSE)
rm(list=ls())
#2.3a
install.packages("MASS")
library(MASS)
names(biopsy)
#2.3b
nrow(biopsy)
train <- sample(x=1:nrow(biopsy), size=nrow(biopsy)/2, replace=FALSE)
biopsy.train = biopsy[train,]
biopsy.test = biopsy[-train,]
#2.3c
res <- lm(formula = class ~ V3 + V4 + V5,Auto.train)
install.packages("MASS")
#2.3b
nrow(biopsy)
train <- sample(x=1:nrow(biopsy), size=nrow(biopsy)/2, replace=FALSE)
biopsy.train = biopsy[train,]
biopsy.test = biopsy[-train,]
res <- lm(formula = class ~ V3 + V4 + V5,Auto.train)
res <- lm(formula = class ~ V3 + V4 + V5,biopsy.train)
print(res)
pairs(biopsy[,2:11])
glm.fit <- glm(formula = class ~ V3 + V4 + V5,biopsy.train, family = binomial)
glm.probs <- predict(object = glm.fit, newdata = biopsy.test, type = "response")
glm.pred <- rep("benign", length(glm.prbs))
glm.pred <- rep("benign", length(glm.probs))
table(biopsy.test$class, glm.pred)
glm.pred[glm.probs > 0.5] <- "malignant"
table(biopsy.test$class, glm.pred)
mean(glm.pred == biopsy.test$class)
glm.fit <- glm(formula = class ~ V3 + V4 + V5,biopsy.train, family = binomial)
glm.probs <- predict(object = glm.fit, newdata = biopsy.test, type = "response")
glm.pred <- rep("benign", length(glm.probs))
glm.pred[glm.probs > 0.5] <- "malignant"
table(biopsy.test$class, glm.pred)
mean
mean(glm.pred == biopsy.test$class)
#4.1d
lda.fit<-lda(formula = class ~ V3 + V4 + V5, data = biopsy.train)
lda.testdata <- predict(object = lda.fit, newdata = biopsy.test)
lda.pred <- lda.testdata$class
table(biopsy.test$class,lda.pred)
mean(lda.pred == biopsy.test$class)
qda.fit <- qda(formula= class ~ V3 + V4 + V5, data = biopsy.train)
qda.testdata <- predict(object = qda.fit, newdata = biopsy.test)
qda.pred <- qda.testdata$class
table(biopsy.test$class,qda.pred)
mean(qda.pred == biopsy.test$class)
biopsy.train.KNN <- as.matrix(biopsy.train[c("V3","V4","V5")])
biopsy.train.KNN <- as.matrix(biopsy.train[c("V3","V4","V5")])
biopsy.train.KNN <- as.matrix(biopsy.train[c("V3","V4","V5")])
biopsy.test.KNN <- as.matrix(biopsy.test[c("V3","V4","V5")])
knn.pred <- knn(train = biopsy.training.KNN, test = biopsy.test.KNN,
c1 = as.matrix(biopsy.training["class"]), k=1)
# 4.1 f
library(class)
biopsy.train.KNN <- as.matrix(biopsy.train[c("V3","V4","V5")])
biopsy.test.KNN <- as.matrix(biopsy.test[c("V3","V4","V5")])
knn.pred <- knn(train = biopsy.training.KNN, test = biopsy.test.KNN,
c1 = as.matrix(biopsy.training["class"]), k=1)
knn.pred <- knn(train = biopsy.training.KNN, test = biopsy.test.KNN,
c1 = as.matrix(biopsy.training["class"]), k=1)
knn.pred <- knn(train = biopsy.training.KNN, test = biopsy.test.KNN,
c1 = as.matrix(biopsy.training["class"]), k=1)
knn.pred <- knn(train = biopsy.training.KNN, test = biopsy.test.KNN,
cl = as.matrix(biopsy.train["class"]), k=1)
knn.pred <- knn(train = biopsy.training.KNN, test = biopsy.test.KNN,
cl = as.matrix(biopsy.train["class"]), k=1)
knn.pred <- knn(train = biopsy.train.KNN, test = biopsy.test.KNN,
cl = as.matrix(biopsy.train["class"]), k=1)
table(biopsy.test$class, knn.pred)
mean(knn.pred == biopst.test$class)
mean(knn.pred == biopsy.test$class)
missclassification <- c()
knn.pred <- knn(train = biopsy.training.KNN, test = biopsy.test.KNN)
missclassification <- c()
for(kt in 1:50)
{
knn.pred <- knn(train = biopsy.training.KNN, test = biopsy.test.KNN,
cl = as.matrix(biopsy.train["class"]), k = kt)
missclassification[kt]= mean(knn.pred != biopsy.test$class)
}
{
knn.pred <- knn(train = biopsy.train.KNN, test = biopsy.test.KNN,
cl = as.matrix(biopsy.train["class"]), k = kt)
missclassification[kt]= mean(knn.pred != biopsy.test$class)
}
for(kt in 1:50)
{
knn.pred <- knn(train = biopsy.train.KNN, test = biopsy.test.KNN,
cl = as.matrix(biopsy.train["class"]), k = kt)
missclassification[kt]= mean(knn.pred != biopsy.test$class)
}
plot(x = 1:50, y = misclassification, type = "l",xlab ="k")
plot(x = 1:50, y = missclassification, type = "l",xlab ="k")
View(res)
clear
clc
clear console
gggg
falsepositiverate <- c()
truepositiverate<-c()
N <- sum(biopsy.test$class == "benign")
P <- sum(biopsy.test$class == "malignant")
# generate data
set.seed(2); N = 100
x1 <- runif(n=N, min = 0, max = 10)
x2 <- runif(n=N, min = 0, max = 10)
y <- rep(1,N)
y[x1<4] <- 0; y[x2<4] <- 0
# learn a logistic regression model
model.fit <- glm(y~x1+x2,family="binomial",data=data.frame(y,x1,x2))
# open a plot with a good size
plot(x1,x2,type="n",main="logistic regression decision boundary")
# classify many points, and plot a colored square around each point
res <- 0.1 # resolution of the squares
{
for (xs2 in seq(0,10,res))
{
pred <- predict(model.fit,newdata=data.frame(x1=xs1,x2=xs2),type="response")
if (pred>.5)
{
polygon(x=c(xs1-res/2,xs1+res/2,xs1+res/2,xs1-res/2),
y=c(xs2-res/2,xs2-res/2,xs2+res/2,xs2+res/2),col=rgb(1,0,0,0.5),border=NA)
}
else
{
polygon(x=c(xs1-res/2,xs1+res/2,xs1+res/2,xs1-res/2),
y=c(xs2-res/2,xs2-res/2,xs2+res/2,xs2+res/2),col=rgb(0,0,1,0.5),border=NA)
}
}
}
for (xs1 in seq(0,10,res))
# plot the data
points(x1[y==0],x2[y==0],pch=16,col="blue"); points(x1[y==1],x2[y==1],pch=16,col="red")
# generate data
set.seed(2); N = 100
x1 <- runif(n=N, min = 0, max = 10)
x2 <- runif(n=N, min = 0, max = 10)
y <- rep(1,N)
y[x1<4] <- 0; y[x2<4] <- 0
# learn a logistic regression model
model.fit <- glm(y~x1+x2,family="binomial",data=data.frame(y,x1,x2))
# open a plot with a good size
plot(x1,x2,type="n",main="logistic regression decision boundary")
# classify many points, and plot a colored square around each point
res <- 0.1 # resolution of the squares
for (xs1 in seq(0,10,res))
{
for (xs2 in seq(0,10,res))
{
pred <- predict(model.fit,newdata=data.frame(x1=xs1,x2=xs2),type="response")
if (pred>.5)
{
polygon(x=c(xs1-res/2,xs1+res/2,xs1+res/2,xs1-res/2),
y=c(xs2-res/2,xs2-res/2,xs2+res/2,xs2+res/2),col=rgb(1,0,0,0.5),border=NA)
}
else
{
polygon(x=c(xs1-res/2,xs1+res/2,xs1+res/2,xs1-res/2),
y=c(xs2-res/2,xs2-res/2,xs2+res/2,xs2+res/2),col=rgb(0,0,1,0.5),border=NA)
}
}
}
# plot the data
points(x1[y==0],x2[y==0],pch=16,col="blue"); points(x1[y==1],x2[y==1],pch=16,col="red")
clear data
set.seed(2); N = 100
x1 <- runif(n=N, min = 0, max = 10)
x2 <- runif(n=N, min = 0, max = 10)
y <- rep(1,N)
y[x1<4] <- 0; y[x2<4] <- 0
# learn a logistic regression model
model.fit <- qda(y~x1+x2,family="binomial",data=data.frame(y,x1,x2))
# open a plot with a good size
plot(x1,x2,type="n",main="logistic regression decision boundary")
# classify many points, and plot a colored square around each point
res <- 0.1 # resolution of the squares
for (xs1 in seq(0,10,res))
{
for (xs2 in seq(0,10,res))
{
pred <- predict(model.fit,newdata=data.frame(x1=xs1,x2=xs2),type="response")
if (pred>.5)
{
polygon(x=c(xs1-res/2,xs1+res/2,xs1+res/2,xs1-res/2),
y=c(xs2-res/2,xs2-res/2,xs2+res/2,xs2+res/2),col=rgb(1,0,0,0.5),border=NA)
}
else
{
polygon(x=c(xs1-res/2,xs1+res/2,xs1+res/2,xs1-res/2),
y=c(xs2-res/2,xs2-res/2,xs2+res/2,xs2+res/2),col=rgb(0,0,1,0.5),border=NA)
}
}
}
# plot the data
points(x1[y==0],x2[y==0],pch=16,col="blue"); points(x1[y==1],x2[y==1],pch=16,col="red")
# generate data
set.seed(2); N = 100
x1 <- runif(n=N, min = 0, max = 10)
x2 <- runif(n=N, min = 0, max = 10)
y <- rep(1,N)
y[x1<4] <- 0; y[x2<4] <- 0
# learn a logistic regression model
model.fit <- qda(y~x1+x2,family="binomial",data=data.frame(y,x1,x2))
# open a plot with a good size
plot(x1,x2,type="n",main="logistic regression decision boundary")
# classify many points, and plot a colored square around each point
res <- 0.1 # resolution of the squares
for (xs1 in seq(0,10,res))
{
for (xs2 in seq(0,10,res))
{
pred <- predict(model.fit,newdata=data.frame(x1=xs1,x2=xs2),type="response")
if (pred>.5)
{
polygon(x=c(xs1-res/2,xs1+res/2,xs1+res/2,xs1-res/2),
y=c(xs2-res/2,xs2-res/2,xs2+res/2,xs2+res/2),col=rgb(1,0,0,0.5),border=NA)
}
else
{
polygon(x=c(xs1-res/2,xs1+res/2,xs1+res/2,xs1-res/2),
y=c(xs2-res/2,xs2-res/2,xs2+res/2,xs2+res/2),col=rgb(0,0,1,0.5),border=NA)
}
}
}
pred
# generate data
set.seed(2); N = 100
x1 <- runif(n=N, min = 0, max = 10)
x2 <- runif(n=N, min = 0, max = 10)
y <- rep(1,N)
y[x1<4] <- 0; y[x2<4] <- 0
# learn a logistic regression model
model.fit <- lda(y~x1+x2,family="binomial",data=data.frame(y,x1,x2))
# open a plot with a good size
plot(x1,x2,type="n",main="logistic regression decision boundary")
# classify many points, and plot a colored square around each point
res <- 0.1 # resolution of the squares
for (xs1 in seq(0,10,res))
{
for (xs2 in seq(0,10,res))
{
pred <- predict(model.fit,newdata=data.frame(x1=xs1,x2=xs2),type="response")
if (pred>.5)
{
polygon(x=c(xs1-res/2,xs1+res/2,xs1+res/2,xs1-res/2),
y=c(xs2-res/2,xs2-res/2,xs2+res/2,xs2+res/2),col=rgb(1,0,0,0.5),border=NA)
}
else
{
polygon(x=c(xs1-res/2,xs1+res/2,xs1+res/2,xs1-res/2),
y=c(xs2-res/2,xs2-res/2,xs2+res/2,xs2+res/2),col=rgb(0,0,1,0.5),border=NA)
}
}
}
# generate data
set.seed(2); N = 100
x1 <- runif(n=N, min = 0, max = 10)
x2 <- runif(n=N, min = 0, max = 10)
y <- rep(1,N)
y[x1<4] <- 0; y[x2<4] <- 0
# learn a logistic regression model
model.fit <- lda(y~x1+x2,family="binomial",data=data.frame(y,x1,x2))
# open a plot with a good size
plot(x1,x2,type="n",main="logistic regression decision boundary")
# classify many points, and plot a colored square around each point
res <- 0.1 # resolution of the squares
for (xs1 in seq(0,10,res))
{
for (xs2 in seq(0,10,res))
{
pred <- predict(model.fit,newdata=data.frame(x1=xs1,x2=xs2)) $posterior[2]
if (pred>.5)
{
polygon(x=c(xs1-res/2,xs1+res/2,xs1+res/2,xs1-res/2),
y=c(xs2-res/2,xs2-res/2,xs2+res/2,xs2+res/2),col=rgb(1,0,0,0.5),border=NA)
}
else
{
polygon(x=c(xs1-res/2,xs1+res/2,xs1+res/2,xs1-res/2),
y=c(xs2-res/2,xs2-res/2,xs2+res/2,xs2+res/2),col=rgb(0,0,1,0.5),border=NA)
}
}
}
# plot the data
points(x1[y==0],x2[y==0],pch=16,col="blue"); points(x1[y==1],x2[y==1],pch=16,col="red")
# generate data
set.seed(2); N = 100
x1 <- runif(n=N, min = 0, max = 10)
x2 <- runif(n=N, min = 0, max = 10)
y <- rep(1,N)
y[x1<4] <- 0; y[x2<4] <- 0
# learn a logistic regression model
model.fit <- qda(y~x1+x2,family="binomial",data=data.frame(y,x1,x2))
# open a plot with a good size
plot(x1,x2,type="n",main="logistic regression decision boundary")
# classify many points, and plot a colored square around each point
res <- 0.1 # resolution of the squares
for (xs1 in seq(0,10,res))
{
for (xs2 in seq(0,10,res))
{
pred <- predict(model.fit,newdata=data.frame(x1=xs1,x2=xs2)) $posterior[2]
if (pred>.5)
{
polygon(x=c(xs1-res/2,xs1+res/2,xs1+res/2,xs1-res/2),
y=c(xs2-res/2,xs2-res/2,xs2+res/2,xs2+res/2),col=rgb(1,0,0,0.5),border=NA)
}
else
{
polygon(x=c(xs1-res/2,xs1+res/2,xs1+res/2,xs1-res/2),
y=c(xs2-res/2,xs2-res/2,xs2+res/2,xs2+res/2),col=rgb(0,0,1,0.5),border=NA)
}
}
}
# plot the data
points(x1[y==0],x2[y==0],pch=16,col="blue"); points(x1[y==1],x2[y==1],pch=16,col="red")
info = list(a = 1)
info$b
is(info$b == NULL)
show(info$b == NULL)
a = list(b=1)
is.null
is.null(a$c)
a = list(1:40)
a
a = lsit[]
a = list(rep(0,40))
a
a[1]
a[[1]]
a
a[1]
a[[4]]
a[1]
a[2]
a(1)
a = list(rep(0,40))
a
a[[1]]
a[[1]][1]
a = (1,2,3,4)
a = [1,2,3,4]
a = 1
a+=2
a
help(dnorm)
help(sum)
a = list(1,2,3,4,5)
a
a/5
a[[]]/5
a
a[]/5
a = list(1,2,3,4,5)
a
a = list(1,2,3)
source('~/Teknisk Fysik/AI/Project 2 - Wheres croc/main.R', echo=TRUE)
source('~/Teknisk Fysik/AI/Project 2 - Wheres croc/main.R', echo=TRUE)
edges
source('~/Teknisk Fysik/AI/Project 2 - Wheres croc/main.R', echo=TRUE)
source('~/Teknisk Fysik/AI/Project 2 - Wheres croc/main.R', echo=TRUE)
source('~/Teknisk Fysik/AI/Project 2 - Wheres croc/main.R', echo=TRUE)
source('~/Teknisk Fysik/AI/Project 2 - Wheres croc/main.R', echo=TRUE)
source('~/Teknisk Fysik/AI/Project 2 - Wheres croc/main.R', echo=TRUE)
source('~/Teknisk Fysik/AI/Project 2 - Wheres croc/main.R', echo=TRUE)
runWheresCroc
source('~/Teknisk Fysik/AI/Project 2 - Wheres croc/main.R', echo=TRUE)
